{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROGRAMACIÓN I\n",
    "\n",
    "Nombre: Madeleine Yameli Romero Rayas\n",
    "\n",
    "Código: 207549458\n",
    "\n",
    "Maestría en Ciencia de los Datos (CUCEA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge de Fin de Curso: El Gran Analizador de Texto Python (GATPy):\n",
    "\n",
    "### Descripción del Challenge\n",
    "Crearás un script de Python denominado GATPy. Este script leerá un archivo de texto provisto por el usuario (por ejemplo, un libro de dominio público de Project Gutenberg). Luego, calculará y presentará lo siguiente:\n",
    "* La frecuencia de cada palabra en el texto.\n",
    "* Las 5 palabras más comunes y su conteo.\n",
    "* La cantidad de palabras únicas en el documento.\n",
    "* Opcional: Una nube de palabras generada a partir del texto.\n",
    "\n",
    "Además, el script generará un archivo de salida .txt con los resultados del análisis y una visualización simple si optas por la funcionalidad opcional.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Busca y elige un libro en español de Project Gutenberg para analizar, ingresa a https://www.gutenberg.org/ \n",
      "El URL que ingresaste no es válido. Por favor, ingresa un URL que empiece con http:// o https:// y tenga un dominio válido.\n",
      "El URL que se analizará es: https://www.gutenberg.org/files/2000/2000-0.txt\n",
      "Se ha creado la imagen nube_de_palabras.png con la nube de palabras del libro.\n",
      "Se ha creado el archivo resultados.txt con el informe de la información del libro.\n"
     ]
    }
   ],
   "source": [
    "# Importamos los módulos necesarios\n",
    "import requests\n",
    "import string\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "nltk.download('stopwords', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Defininimos una variable que contenga los signos de puntuación para excluirlos\n",
    "PUNTUACION = string.punctuation + \"¿¡—»\"\n",
    "\n",
    "# Solicitamos al usuario el URL del libro de Project Gutenberg\n",
    "print(\"Busca y elige un libro en español de Project Gutenberg para analizar, ingresa a https://www.gutenberg.org/ \")\n",
    "url = input(\"Ingresa el URL del libro de Project Gutenber que quieras analizar: \")\n",
    "# Validamos que el URL sea válido\n",
    "while not urlparse(url).scheme or not urlparse(url).netloc:\n",
    "    print(\"El URL que ingresaste no es válido. Por favor, ingresa un URL que empiece con http:// o https:// y tenga un dominio válido.\")\n",
    "    url = input(\"Ingresa el URL del libro de Project Gutenber que quieras analizar: \")\n",
    "\n",
    "# Imprimimos un mensaje de confirmación del URL ingresado\n",
    "print(\"El URL que se analizará es:\", url)\n",
    "\n",
    "# Obtenemos el contenido del libro como una cadena de bytes para poder leer los acentos correctamente\n",
    "response = requests.get(url)\n",
    "texto_bytes = response.content\n",
    "# Decodificamos el texto como UTF-8\n",
    "texto = texto_bytes.decode(\"utf-8\")\n",
    "\n",
    "def contar_palabras(texto):\n",
    "    \"\"\"Cuenta las ocurrencias de cada palabra en un texto.\"\"\"\n",
    "    # Convertimos el texto a minúsculas\n",
    "    texto = texto.lower()\n",
    "    # Eliminamos los signos de puntuación\n",
    "    tabla = str.maketrans(\"\", \"\", PUNTUACION)\n",
    "    texto = texto.translate(tabla)\n",
    "    # Dividimos el texto en palabras\n",
    "    palabras = texto.split()\n",
    "    # Creamos un diccionario vacío para almacenar las ocurrencias\n",
    "    ocurrencias = {}\n",
    "    # Recorremos las palabras del texto\n",
    "    for palabra in palabras:\n",
    "        # Incrementamos el contador de la palabra o lo iniciamos en 1\n",
    "        ocurrencias[palabra] = ocurrencias.get(palabra, 0) + 1\n",
    "    return ocurrencias\n",
    "\n",
    "# Contamos las palabras del texto\n",
    "ocurrencias = contar_palabras(texto)\n",
    "# Ordenamos el diccionario de ocurrencias por el valor de las palabras\n",
    "ocurrencias = sorted(ocurrencias.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Obtenemos el conteo de palabras únicas\n",
    "unicas = len(ocurrencias)\n",
    "\n",
    "# Obtenemos las 5 palabras más comunes y su ocurrencia\n",
    "top5 = ocurrencias[:5]\n",
    "\n",
    "# Creamos un conjunto de stopwords en español para quitarlas de la nube\n",
    "stopwords_es = set(stopwords.words('spanish'))\n",
    "\n",
    "# Creamos una nube de palabras a partir del texto\n",
    "nube = WordCloud(width=800, height=400, background_color=\"white\", stopwords=stopwords_es)\n",
    "nube.generate_from_text(texto)\n",
    "\n",
    "# Guardamos la nube de palabras como una imagen\n",
    "nube.to_file(\"nube_de_palabras.png\")\n",
    "\n",
    "# Imprimimos un mensaje de confirmación de la creación de la imagen\n",
    "print(\"Se ha creado la imagen nube_de_palabras.png con la nube de palabras del libro.\")\n",
    "\n",
    "# Creamos una cadena de texto con el formato del informe de resultados\n",
    "informe = f\"\"\"EL LIBRO ANALIZADO SE ENCUENTRA EN: {url}\n",
    "\n",
    "ESTE LIBRO TIENE {unicas} PALABRAS ÚNICAS\n",
    "\n",
    "LAS 5 PALABRAS MÁS COMUNES Y SU CONTEO SON:\n",
    "1. {top5[0][0]}: {top5[0][1]}\n",
    "2. {top5[1][0]}: {top5[1][1]}\n",
    "3. {top5[2][0]}: {top5[2][1]}\n",
    "4. {top5[3][0]}: {top5[3][1]}\n",
    "5. {top5[4][0]}: {top5[4][1]}\n",
    "\n",
    "LA FRECUENCIA DE CADA PALABRA EN EL LIBRO SE ENLISTA A CONTINUACIÓN:\n",
    "\"\"\"\n",
    "# Añadimos cada palabra y su frecuencia al informe\n",
    "for palabra, frecuencia in ocurrencias:\n",
    "    informe += f\"{palabra}: {frecuencia}\\n\"\n",
    "\n",
    "# Creamos un archivo de texto con el nombre 'resultados'\n",
    "archivo = open(\"resultados.txt\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "# Escribimos el contenido del informe en el archivo\n",
    "archivo.write(informe)\n",
    "\n",
    "# Cerramos el archivo\n",
    "archivo.close()\n",
    "\n",
    "# Imprimimos un mensaje de confirmación de la creación del informe\n",
    "print(\"Se ha creado el archivo resultados.txt con el informe de la información del libro.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "progra_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
